<!DOCTYPE html>
<html>
    <head>
        <meta name='viewport' content='width=device-width, initial-scale=1.0'/>
        <link rel="stylesheet" href="index.css">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Comfortaa:wght@400;700&family=Inter:wght@400;900&family=Lato&family=Mulish:wght@400;800&family=Nunito:wght@400;800&family=Space+Mono:wght@400;700&display=swap" rel="stylesheet">
        <!-- <script src="https://kit.fontawesome.com/defacc6cf5.js" crossorigin="anonymous"></script> -->
        <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet"> -->
        <!-- <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet"> -->
        <link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.1.1/css/all.css" integrity="sha384-/frq1SRXYH/bSyou/HUp/hib7RVN1TawQYja658FEOodR/FQBKVqT9Ol+Oz3Olq5" crossorigin="anonymous">
        
        <title>Vyom Thakkar's Portfolio Site</title>
        <link rel="icon" type="image/x-icon" href="images/favicon.ico">
    </head>
    <body>
        <header>
            <nav id="navigation">
                <span class="back-icon-nav"><a href="index.html"> <i class="fa-solid fa-arrow-left"></i> </a></span> Synthetic X-Ray Image Generation
            </nav>
          </header>
          <main class="project-content">
            <!-- <h1 class="project-desc-heading"><span class="back-icon-head"><a href="index.html"><i class="fa-solid fa-arrow-left"></i></a></span>Noteboost</h1>             -->
            <h1 class="project-desc-heading">Synthetic X-Ray Image Generation</h1>
            <!-- <img src="images/ddx2.png" alt="" class="project-img"> -->
            <h3>Project Info:</h3>
            <div class="project-desc-info">
                <p class="normal-p"><strong>Team Size:</strong> 2 </p>
            </div>
            <!-- <div class="project-desc-info">
                <p class="normal-p"><strong>My roles and responsibilities:</strong><ul><li>Building the frontend of the student view (React)</li> <li>Implementing backend, including authentication (Node.js + Passport.js)</li>
                <li>Implementing version 2 (now deprecated) of the NLP algorithm for automated short-answer grading</li>
                <li>Building data pipeline and preprocessing</li>
                </ul></p>
            </div> -->
            <div class="project-desc-info">
                <p class="normal-p"><strong>Technologies/Tools used:</strong> <span class="badge-desc pytorch-desc">Pytorch</span>  <span class="badge-desc python-desc">Python</span> </p>
            </div>
            <div class="project-desc-info">
                <p class="normal-p"><strong>Project Timeline:</strong> February 2021 - May 2021</p>
            </div>
            <div class="project-desc-content">
                <p>This project was motivated by the ongoing COVID pandemic with the aim of experimenting with computer vision techniques that could help in diagnosing COVID.
                    The X-ray dataset that was obtained from Kaggle had a limited number of COVID X-rays, hence our project focused on a technique to augment this dataset with the aim of improving the classification accuracy of a COVID detection model.
                </p>
                <p>The project consists of two components: <strong>Generative Adversarial Network (GAN)</strong> to generate new images to augment the existing COVID X-ray dataset, and

                    <strong>Convolutional Neural Network (CNN) Model</strong> to help classify whether a patient X-ray has COVID or not.</p>
                <!-- <img src="" alt="" class="project-img">  -->
                <br>
                <h3>Generative Adversial Network:</h3>
                <p>We wanted to learn the distribution of the input Chest X-Ray training data which would in turn help us to generate new covid/normal X-Ray images.
                    We designed a <strong>Conditional GAN</strong> for the purpose of image generation.
                    The Conditional GAN takes in labels and noise as inputs and outputs an image based on the input label.
                    The architecture of the GAN is included below:
                    </p>
                <img src="images/gan.png" alt="" class="project-img2">
                <h3>GAN training: </h3>
                <p>We had a total of 7232 images for training (3616 covid images and 3616 normal images).
                    We trained the discriminator 1 step for every K (=10) steps that we trained the generator. This helps to prevent the discriminator from learning too fast which can cause the generator to diverge and create noisy results.
                    The discriminator uses the Binary Cross Entropy Loss function to discriminate between real and fake images. 
                    Following are the results from running the GAN for 10 epochs:
                    </p>
                    <img src="images/gan2.png" alt="" class="project-img2">
                <h3>Convolutional Neural Network:</h3>
                <p>We experimented with three pretrained (on Imagenet) models: InceptionV3, Resnet50, VGG16 as the backbone.
                    We removed the original fully-connected layers and augmented with custom fully-connected layers for classification task at hand. 
                    We froze the layers of the pretrained models.
                    The data was split in a 0.6-0.2-0.2 train,validation and test split. The data has perfect class balance and each set has equal number of covid and normal examples.
                </p>
                <p>The architecture of our CNN model is included below:</p>
                <img src="images/cnn.png" alt="" class="project-img">
                <p>The performance of our model on the original Kaggle dataset:</p>
                <img src="images/cnn-res1.png" alt="" class="project-img3">
                <p>The performance of our model on the augmented dataset consisting of images generated by the GAN:</p>
                <img src="images/cnn-res2.png" alt="" class="project-img3">
                <h3>Learnings:</h3>
                <p>
                    <ul>
                        <li><p>We found that training the Conditional GAN was a difficult task, because of the multitude of hyperparameters involved which influence whether the generator and discriminator are able to learn from each other or not.
                        </p></li>
                        <li><p>Although the GAN did not produce great quality (visually) images, it did seem that it was able to encode some meaningful data because we observed improved performance on two out of three models after augmenting them with the GAN generated data.</p> </li>
                        <li><p>Our best model is the GAN data augmented VGG16 which produced a test set accuracy of 0.9675.</p></li>
                    </ul>
                </p>
                <div class="footer"><a href="index.html"><i class="fa-solid fa-arrow-left"></i></a></div>
            </div>

            
          </main>
          <script src="noteboost.js"></script>

    </body>
</html>